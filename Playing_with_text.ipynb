{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kamrankhan69/Playing-With-Text/blob/main/Playing_with_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0iBh_whCeNt",
        "outputId": "32096224-edf5-45e0-b0f2-6bc29d806ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BygC1S-6FBgH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGw251VRGwLl"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/training.1600000.processed.noemoticon.csv\", encoding='latin-1',header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCdlcESVJ46X",
        "outputId": "92dae478-f889-4486-c6a3-426694ee3372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         0           1                             2         3  \\\n",
            "0        0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
            "1        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
            "2        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
            "3        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "4        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "...     ..         ...                           ...       ...   \n",
            "1599995  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
            "1599996  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
            "1599997  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
            "1599998  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
            "1599999  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
            "\n",
            "                       4                                                  5  \n",
            "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
            "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
            "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
            "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
            "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
            "...                  ...                                                ...  \n",
            "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
            "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
            "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
            "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
            "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
            "\n",
            "[1600000 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fBQaSRLaKPDB",
        "outputId": "d7e14d37-9d6d-40d9-ccd9-461916832ab2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target         ids                          date      flag  \\\n",
              "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "...         ...         ...                           ...       ...   \n",
              "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
              "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
              "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
              "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
              "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
              "\n",
              "                    user                                               text  \n",
              "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
              "...                  ...                                                ...  \n",
              "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
              "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
              "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
              "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
              "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
              "\n",
              "[1600000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-973a2e2a-e122-4c17-9709-26763b865519\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601966</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>AmandaMarie1028</td>\n",
              "      <td>Just woke up. Having no school is the best fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601969</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>TheWDBoards</td>\n",
              "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601991</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>bpbabe</td>\n",
              "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602064</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>tinydiamondz</td>\n",
              "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602129</td>\n",
              "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>RyanTrevMorris</td>\n",
              "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1600000 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-973a2e2a-e122-4c17-9709-26763b865519')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-973a2e2a-e122-4c17-9709-26763b865519 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-973a2e2a-e122-4c17-9709-26763b865519');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "new_columns = [\"target\",\"ids\",\"date\",\"flag\",\"user\",\"text\"]\n",
        "\n",
        "for j in range(len(df.columns)):\n",
        "    old = df.columns[j]\n",
        "    new = new_columns[j]\n",
        "    df = df.rename(columns = {old:new})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Agx5sEtN3EH",
        "outputId": "eacdf204-984c-44ec-eb22-f9bcd13870fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    800000\n",
              "4    800000\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AuSG2YJL23G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34337cc-72cb-4b78-ab1f-7fa967535314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "stemmer = WordNetLemmatizer()\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "def preprocess(sentence):\n",
        "    tweet = re.sub(r\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", ' ', sentence)\n",
        "\n",
        "    # remove all single characters\n",
        "    tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', tweet)\n",
        "\n",
        "    # Substituting multiple spaces with single space\n",
        "    tweet = re.sub(r'\\s+', ' ', tweet, flags=re.I)\n",
        "\n",
        "    # Converting to Lowercase\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    # Lemmatization\n",
        "    tweet = tweet.split()\n",
        "\n",
        "    tweet = [stemmer.lemmatize(word) for word in tweet]\n",
        "    tweet = ' '.join(tweet)\n",
        "    return tweet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "pfShVwgLJPxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLhuQCyMPDeM",
        "outputId": "8482dc6d-2837-4a99-85dc-1ed83597c009"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          awww that a bummer you shoulda got david carr ...\n",
              "1          is upset that he can update his facebook by te...\n",
              "2          dived many time for the ball managed to save 5...\n",
              "3               my whole body feel itchy and like it on fire\n",
              "4          no it not behaving at all m mad why am here be...\n",
              "                                 ...                        \n",
              "1599995    just woke up having no school is the best feel...\n",
              "1599996      thewdb com very cool to hear old walt interview\n",
              "1599997    are you ready for your mojo makeover ask me fo...\n",
              "1599998    happy 38th birthday to my boo of alll time tup...\n",
              "1599999    happy charitytuesday thenspcc sparkscharity sp...\n",
              "Name: text, Length: 1600000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "df['target'] = df['target'].replace(4,1)\n",
        "df['target']\n",
        "df['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqAmdlG5PQLI"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "max_features = 10000\n",
        "maxlen = 140\n",
        "X = df.iloc[:,5]\n",
        "y = df.iloc[:,0]\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3,stratify=y,random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tteo1CF00h2O",
        "outputId": "71d70d13-67a0-4179-97b0-cae2b39357e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train\n",
        "\n",
        "precisionList = []\n",
        "accuracyList = []\n",
        "recallList = []\n",
        "F1List = []\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vU_1FvcA-niN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-RGYT9lbHKX"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "text_vectorization = layers.TextVectorization (max_tokens=10000, output_mode=\"int\")\n",
        "text_vectorization.adapt(X)\n",
        "X_train = text_vectorization(X_train)\n",
        "X_test = text_vectorization(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE1Fz17XyOMg"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(X_train,open( \"/content/drive/MyDrive/x_train1.p\", \"wb\" ))\n",
        "pickle.dump(X_test, open( \"/content/drive/MyDrive/x_test1.p\", \"wb\" ))\n",
        "pickle.dump(y_train, open( \"/content/drive/MyDrive/y_train1.p\", \"wb\" ))\n",
        "pickle.dump(y_test, open( \"/content/drive/MyDrive/y_test1.p\", \"wb\" ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "179C80Sf1rXq"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train1 = pickle.load(open(\"/content/drive/MyDrive/x_train1.p\",\"rb\"))\n",
        "X_test1 = pickle.load(open(\"/content/drive/MyDrive/x_test1.p\",\"rb\"))\n",
        "y_train1 = pickle.load(open(\"/content/drive/MyDrive/y_train1.p\",\"rb\"))\n",
        "y_test1 = pickle.load(open(\"/content/drive/MyDrive/y_test1.p\",\"rb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 1 using simple RNN with 2 layers **"
      ],
      "metadata": {
        "id": "M1BohV3XctCV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArHqvtgOP8Ot",
        "outputId": "f172ad2c-303c-4e22-8d1c-eb8b92b8ff68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3500/3500 [==============================] - 124s 35ms/step - loss: 0.4988 - acc: 0.7585 - val_loss: 0.4415 - val_acc: 0.7962\n",
            "Epoch 2/5\n",
            "3500/3500 [==============================] - 127s 36ms/step - loss: 0.4383 - acc: 0.7995 - val_loss: 0.4537 - val_acc: 0.7920\n",
            "Epoch 3/5\n",
            "3500/3500 [==============================] - 105s 30ms/step - loss: 0.4256 - acc: 0.8059 - val_loss: 0.4331 - val_acc: 0.8016\n",
            "Epoch 4/5\n",
            "3500/3500 [==============================] - 102s 29ms/step - loss: 0.4172 - acc: 0.8105 - val_loss: 0.4435 - val_acc: 0.7970\n",
            "Epoch 5/5\n",
            "3500/3500 [==============================] - 103s 29ms/step - loss: 0.4102 - acc: 0.8148 - val_loss: 0.4290 - val_acc: 0.8050\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "max_features = 10000\n",
        "max_length = 140\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, max_length))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train1, y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=256,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "QtW21gV3RYKU",
        "outputId": "d5d775e8-e428-4326-fdee-605a01116c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 89s 6ms/step - loss: 0.4785 - acc: 0.7790\n",
            "15000/15000 [==============================] - 75s 5ms/step\n",
            "0.7790104166666667\n",
            "0.8688641984829539\n",
            "0.6572125\n",
            "0.7483613538076136\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d3bfb5c611d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0maccuracyList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprecisionList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mrecallList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracyList' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))\n"
      ],
      "metadata": {
        "id": "2I5od02FRJ6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.7790104166666667)\n",
        "# precisionList.append(0.8688641984829539)\n",
        "# recallList.append(0.6572125)\n",
        "# F1List.append(0.7483613538076136)\n"
      ],
      "metadata": {
        "id": "LvTfOOAv7Ik7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 2 using simple RNN with 3 layers **"
      ],
      "metadata": {
        "id": "MWeA-hvZc1aU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000\n",
        "max_length = 140\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, max_length))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train1, y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx5d_7mELaNT",
        "outputId": "8a7f091a-b82b-4fe0-82dd-51d40bed24bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 69s 39ms/step - loss: 0.4898 - acc: 0.7703 - val_loss: 0.4628 - val_acc: 0.7900\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 62s 35ms/step - loss: 0.4395 - acc: 0.7984 - val_loss: 0.4348 - val_acc: 0.7979\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 64s 36ms/step - loss: 0.4248 - acc: 0.8058 - val_loss: 0.4260 - val_acc: 0.8059\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 62s 35ms/step - loss: 0.4153 - acc: 0.8114 - val_loss: 0.4318 - val_acc: 0.8031\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 63s 36ms/step - loss: 0.4080 - acc: 0.8152 - val_loss: 0.4217 - val_acc: 0.8078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GkRAxrbQkb7",
        "outputId": "35b8e469-0ab6-4b4d-ddea-796d25735939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 91s 6ms/step - loss: 0.4342 - acc: 0.7971\n",
            "15000/15000 [==============================] - 77s 5ms/step\n",
            "0.797075\n",
            "0.762969984435281\n",
            "0.8619208333333334\n",
            "0.8094325078356412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "id": "VvvwN0cbRXJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.797075)\n",
        "# precisionList.append(0.762969984435281)\n",
        "# recallList.append(0.8619208333333334)\n",
        "# F1List.append(0.8094325078356412)\n"
      ],
      "metadata": {
        "id": "xsy-DO8R7dhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 3 using simple RNN with 2 layers using pre compiled GLove word emmbadding  **"
      ],
      "metadata": {
        "id": "Z5XrGifDdBUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "path_to_glove_file = \"/content/drive/MyDrive/glove.6B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((10000, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i <10000:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 100,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "id": "ABMYJP0JVY93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d93aa1-7c00-43ac-d7f3-976e0932519d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 32)                4256      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,008,481\n",
            "Trainable params: 8,481\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 41s 23ms/step - loss: 0.5822 - acc: 0.6947 - val_loss: 0.5510 - val_acc: 0.7191\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 37s 21ms/step - loss: 0.5454 - acc: 0.7252 - val_loss: 0.5260 - val_acc: 0.7411\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 40s 23ms/step - loss: 0.5281 - acc: 0.7391 - val_loss: 0.5138 - val_acc: 0.7463\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 36s 20ms/step - loss: 0.5163 - acc: 0.7474 - val_loss: 0.5025 - val_acc: 0.7585\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 36s 20ms/step - loss: 0.5079 - acc: 0.7527 - val_loss: 0.4941 - val_acc: 0.7627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gbQDlzJqrNw",
        "outputId": "4dcec06a-79ec-43a6-add6-94a6303e33f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 95s 6ms/step - loss: 0.5056 - acc: 0.7596\n",
            "15000/15000 [==============================] - 75s 5ms/step\n",
            "0.7596333333333334\n",
            "0.7383743171489342\n",
            "0.804225\n",
            "0.7698941372625666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "id": "rG45FHGOTcyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.7596333333333334)\n",
        "# precisionList.append(0.7383743171489342)\n",
        "# recallList.append(0.804225)\n",
        "# F1List.append(0.7698941372625666)"
      ],
      "metadata": {
        "id": "V-YBrE1N72jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 4 using simple RNN with 3 layers using pre compiled GLove word emmbadding **"
      ],
      "metadata": {
        "id": "PSqrIlQfdQ96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 100,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZxnuJbWvMEh",
        "outputId": "9347a7d7-cc74-471f-b551-92e6dbfa8253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 32)                4256      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,018,849\n",
            "Trainable params: 18,849\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 40s 22ms/step - loss: 0.5840 - acc: 0.6937 - val_loss: 0.5556 - val_acc: 0.7147\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 37s 21ms/step - loss: 0.5500 - acc: 0.7216 - val_loss: 0.5354 - val_acc: 0.7329\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 36s 21ms/step - loss: 0.5331 - acc: 0.7341 - val_loss: 0.5163 - val_acc: 0.7450\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 36s 21ms/step - loss: 0.5216 - acc: 0.7426 - val_loss: 0.5104 - val_acc: 0.7508\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 37s 21ms/step - loss: 0.5130 - acc: 0.7492 - val_loss: 0.5000 - val_acc: 0.7594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu690Ml3US8-",
        "outputId": "8d6e15df-578f-41a3-bddf-8329bdfef180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 94s 6ms/step - loss: 0.5186 - acc: 0.7596\n",
            "15000/15000 [==============================] - 77s 5ms/step\n",
            "0.7596\n",
            "0.7585056593753112\n",
            "0.7617166666666667\n",
            "0.7601077718828481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.7596)\n",
        "# precisionList.append(0.7585056593753112)\n",
        "# recallList.append(0.7617166666666667)\n",
        "# F1List.append(0.7601077718828481)"
      ],
      "metadata": {
        "id": "uGIlHSFK8Oei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 5 using simple RNN with 2 layers using pre compiled GLove-twitter word emmbadding**"
      ],
      "metadata": {
        "id": "ZVqvy7XhdYoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "path_to_glove_file = \"/content/drive/MyDrive/glove.twitter.27B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((10000, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i <10000:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 100,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2qaHcUSV3U5",
        "outputId": "d3d5ed26-ab4e-48e2-8af9-04d07c762926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, 32)                4256      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,008,481\n",
            "Trainable params: 8,481\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 43s 24ms/step - loss: 0.5314 - acc: 0.7385 - val_loss: 0.4988 - val_acc: 0.7590\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 41s 24ms/step - loss: 0.4971 - acc: 0.7602 - val_loss: 0.4977 - val_acc: 0.7552\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 36s 21ms/step - loss: 0.4839 - acc: 0.7685 - val_loss: 0.4729 - val_acc: 0.7761\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 37s 21ms/step - loss: 0.4751 - acc: 0.7741 - val_loss: 0.4869 - val_acc: 0.7739\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 39s 22ms/step - loss: 0.4691 - acc: 0.7782 - val_loss: 0.4641 - val_acc: 0.7801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D8v7nbfW8KJ",
        "outputId": "752f7fd8-ea62-4541-f4d7-218711a83974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 89s 6ms/step - loss: 0.4616 - acc: 0.7833\n",
            "15000/15000 [==============================] - 75s 5ms/step\n",
            "0.78329375\n",
            "0.7892215874528354\n",
            "0.7730458333333333\n",
            "0.7810499683211914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.78329375)\n",
        "# precisionList.append(0.7892215874528354)\n",
        "# recallList.append(0.7730458333333333)\n",
        "# F1List.append(0.7810499683211914)"
      ],
      "metadata": {
        "id": "JgVVF0OX8lQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 6 using simple RNN with 3 layers using pre compiled GLove-twitter word emmbadding **"
      ],
      "metadata": {
        "id": "NycLfFTjdjOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 100,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhDY-b7HXAYQ",
        "outputId": "adda099d-c8e5-420b-fd12-616c8debbb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    (None, 32)                4256      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,018,849\n",
            "Trainable params: 18,849\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 37s 21ms/step - loss: 0.5346 - acc: 0.7382 - val_loss: 0.5094 - val_acc: 0.7523\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 36s 21ms/step - loss: 0.5060 - acc: 0.7551 - val_loss: 0.5034 - val_acc: 0.7624\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 36s 21ms/step - loss: 0.4941 - acc: 0.7632 - val_loss: 0.4887 - val_acc: 0.7660\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 36s 20ms/step - loss: 0.4865 - acc: 0.7680 - val_loss: 0.4923 - val_acc: 0.7662\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 37s 21ms/step - loss: 0.4808 - acc: 0.7721 - val_loss: 0.4882 - val_acc: 0.7667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11xfnrGsXGas",
        "outputId": "7f4e660e-6884-4f44-e13f-4ad7114b4433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 104s 7ms/step - loss: 0.4817 - acc: 0.7702\n",
            "15000/15000 [==============================] - 80s 5ms/step\n",
            "0.7702104166666667\n",
            "0.809772198577495\n",
            "0.7063541666666666\n",
            "0.7545360065338967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.7702104166666667)\n",
        "# precisionList.append(0.809772198577495)\n",
        "# recallList.append(0.7063541666666666)\n",
        "# F1List.append(0.7545360065338967)"
      ],
      "metadata": {
        "id": "-rW9fJ6OZPKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 7 using LSTM with 2 layers **"
      ],
      "metadata": {
        "id": "-592D8z7dtPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "from keras.models import Sequential\n",
        "max_features = 10000\n",
        "max_length = 140\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, max_length))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train1, y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=256,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B2LsrFKZTd6",
        "outputId": "63d5d7cc-d2b1-4528-8b9b-ae973fa4ee78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3500/3500 [==============================] - 34s 8ms/step - loss: 0.4498 - acc: 0.7886 - val_loss: 0.4201 - val_acc: 0.8095\n",
            "Epoch 2/5\n",
            "3500/3500 [==============================] - 30s 9ms/step - loss: 0.4088 - acc: 0.8133 - val_loss: 0.4083 - val_acc: 0.8144\n",
            "Epoch 3/5\n",
            "3500/3500 [==============================] - 28s 8ms/step - loss: 0.3949 - acc: 0.8212 - val_loss: 0.3996 - val_acc: 0.8184\n",
            "Epoch 4/5\n",
            "3500/3500 [==============================] - 29s 8ms/step - loss: 0.3846 - acc: 0.8266 - val_loss: 0.3945 - val_acc: 0.8205\n",
            "Epoch 5/5\n",
            "3500/3500 [==============================] - 31s 9ms/step - loss: 0.3766 - acc: 0.8308 - val_loss: 0.3904 - val_acc: 0.8233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNox15piZvYT",
        "outputId": "1b1d2222-993e-4313-b7f6-7ce75c6dca45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 58s 4ms/step - loss: 0.4002 - acc: 0.8185\n",
            "15000/15000 [==============================] - 43s 3ms/step\n",
            "0.8185145833333334\n",
            "0.7897683551357232\n",
            "0.8681166666666666\n",
            "0.8270912190929498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.8185145833333334)\n",
        "# precisionList.append(0.7897683551357232)\n",
        "# recallList.append(0.8681166666666666)\n",
        "# F1List.append(0.8270912190929498)"
      ],
      "metadata": {
        "id": "uhRJa82H9dXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Exprement 8 using LSTM with 3 layers*"
      ],
      "metadata": {
        "id": "69OtX8KJdzja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000\n",
        "max_length = 140\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, max_length))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train1, y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=256,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNNT8DQHaCP4",
        "outputId": "f7ae6bdc-f1d0-4f55-8a26-15db33510786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3500/3500 [==============================] - 30s 8ms/step - loss: 0.4561 - acc: 0.7831 - val_loss: 0.4179 - val_acc: 0.8092\n",
            "Epoch 2/5\n",
            "3500/3500 [==============================] - 30s 9ms/step - loss: 0.4088 - acc: 0.8139 - val_loss: 0.4038 - val_acc: 0.8154\n",
            "Epoch 3/5\n",
            "3500/3500 [==============================] - 28s 8ms/step - loss: 0.3941 - acc: 0.8218 - val_loss: 0.4102 - val_acc: 0.8167\n",
            "Epoch 4/5\n",
            "3500/3500 [==============================] - 28s 8ms/step - loss: 0.3836 - acc: 0.8275 - val_loss: 0.3941 - val_acc: 0.8223\n",
            "Epoch 5/5\n",
            "3500/3500 [==============================] - 28s 8ms/step - loss: 0.3756 - acc: 0.8315 - val_loss: 0.3913 - val_acc: 0.8241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCL1V0oSaLlP",
        "outputId": "f2001e7f-9e77-4f6d-8332-06587df8abdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 58s 4ms/step - loss: 0.3952 - acc: 0.8234\n",
            "15000/15000 [==============================] - 42s 3ms/step\n",
            "0.8233625\n",
            "0.8126490589145288\n",
            "0.8404958333333333\n",
            "0.8263379104673265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.8233625)\n",
        "# precisionList.append(0.8126490589145288)\n",
        "# recallList.append(0.8404958333333333)\n",
        "# F1List.append(0.8263379104673265)"
      ],
      "metadata": {
        "id": "beQqCFTk9zH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Exprement 9 using LSTM with 2 layers using pre compiled GLove word\n",
        "#  emmbadding*"
      ],
      "metadata": {
        "id": "3N5Sz-Gfd8XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = \"/content/drive/MyDrive/glove.6B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((10000, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i <10000:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 100,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssUTlCx-aa0I",
        "outputId": "2db0d857-b75f-490e-c02c-f722bf9cad42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 32)                17024     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,021,249\n",
            "Trainable params: 21,249\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 14s 7ms/step - loss: 0.5261 - acc: 0.7362 - val_loss: 0.4920 - val_acc: 0.7604\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 13s 7ms/step - loss: 0.4766 - acc: 0.7718 - val_loss: 0.4590 - val_acc: 0.7838\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 13s 7ms/step - loss: 0.4591 - acc: 0.7830 - val_loss: 0.4515 - val_acc: 0.7892\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 12s 7ms/step - loss: 0.4477 - acc: 0.7899 - val_loss: 0.4406 - val_acc: 0.7946\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 12s 7ms/step - loss: 0.4395 - acc: 0.7950 - val_loss: 0.4393 - val_acc: 0.7956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yERMJxhajvN",
        "outputId": "71decf4d-a21f-4366-dc91-4c2896c1f524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 69s 5ms/step - loss: 0.4494 - acc: 0.7948\n",
            "15000/15000 [==============================] - 48s 3ms/step\n",
            "0.7948166666666666\n",
            "0.7731470043236566\n",
            "0.8344833333333334\n",
            "0.8026450785508176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.7948166666666666)\n",
        "# precisionList.append(0.7731470043236566)\n",
        "# recallList.append(0.8344833333333334)\n",
        "# F1List.append(0.8026450785508176)"
      ],
      "metadata": {
        "id": "bH37ofr1992s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 10 using LSTM with 3 layers using pre compiled GLove word emmbadding **"
      ],
      "metadata": {
        "id": "bRqOzKLmeCCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 100,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8WcdrffalBs",
        "outputId": "60deccb6-fc37-46e5-b062-b401f8e28b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32)                17024     \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,031,617\n",
            "Trainable params: 31,617\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 20s 10ms/step - loss: 0.5288 - acc: 0.7338 - val_loss: 0.5652 - val_acc: 0.7216\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 17s 10ms/step - loss: 0.4776 - acc: 0.7709 - val_loss: 0.4616 - val_acc: 0.7790\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 18s 10ms/step - loss: 0.4599 - acc: 0.7822 - val_loss: 0.4494 - val_acc: 0.7875\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 14s 8ms/step - loss: 0.4491 - acc: 0.7888 - val_loss: 0.4417 - val_acc: 0.7932\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 16s 9ms/step - loss: 0.4414 - acc: 0.7930 - val_loss: 0.4494 - val_acc: 0.7910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEduMth5atFK",
        "outputId": "dd684dcb-7d4d-4916-a6b5-8bb8d7a460b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 66s 4ms/step - loss: 0.4861 - acc: 0.7869\n",
            "15000/15000 [==============================] - 47s 3ms/step\n",
            "0.7868770833333333\n",
            "0.7488371420620263\n",
            "0.8633125\n",
            "0.802010493739948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.7868770833333333)\n",
        "# precisionList.append(0.7488371420620263)\n",
        "# recallList.append(0.8633125)\n",
        "# F1List.append(0.802010493739948)"
      ],
      "metadata": {
        "id": "nBD8qOfU--GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 11 using LSTM with 2 layers using pre compiled GLove-twitter word emmbadding **"
      ],
      "metadata": {
        "id": "ulmGeknaeLMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = \"/content/drive/MyDrive/glove.twitter.27B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((10000, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i <10000:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 100,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX_M-G79cYSN",
        "outputId": "dc318145-ae17-4e66-d03c-41554c6dafd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 32)                17024     \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,021,249\n",
            "Trainable params: 21,249\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 18s 9ms/step - loss: 0.4838 - acc: 0.7662 - val_loss: 0.4622 - val_acc: 0.7814\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 15s 8ms/step - loss: 0.4450 - acc: 0.7910 - val_loss: 0.4404 - val_acc: 0.7932\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 12s 7ms/step - loss: 0.4323 - acc: 0.7989 - val_loss: 0.4266 - val_acc: 0.8024\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 12s 7ms/step - loss: 0.4238 - acc: 0.8037 - val_loss: 0.4208 - val_acc: 0.8060\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 15s 8ms/step - loss: 0.4175 - acc: 0.8075 - val_loss: 0.4162 - val_acc: 0.8066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "id": "zHKbnOR7ccvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.7968770833333333)\n",
        "# precisionList.append(0.7588371420620263)\n",
        "# recallList.append(0.7633125)\n",
        "# F1List.append(0.802010493739948)"
      ],
      "metadata": {
        "id": "QwFu4VRYBAMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exprement 12 using LSTM with 3 layers using pre compiled GLove-twitter word emmbadding **"
      ],
      "metadata": {
        "id": "eisL5nqzeQwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 100,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6cnAzhOchRU",
        "outputId": "fd02911e-4c0f-4376-e68a-f6a4b57b50f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 32)                17024     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,031,617\n",
            "Trainable params: 31,617\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 16s 8ms/step - loss: 0.4822 - acc: 0.7672 - val_loss: 0.4516 - val_acc: 0.7882\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 13s 7ms/step - loss: 0.4451 - acc: 0.7913 - val_loss: 0.4417 - val_acc: 0.7943\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 13s 8ms/step - loss: 0.4326 - acc: 0.7989 - val_loss: 0.4286 - val_acc: 0.8017\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 14s 8ms/step - loss: 0.4246 - acc: 0.8036 - val_loss: 0.4318 - val_acc: 0.8045\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 13s 8ms/step - loss: 0.4187 - acc: 0.8068 - val_loss: 0.4308 - val_acc: 0.8059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "accuracyList.append(accuracy_score(y_test, y_predict.round()))\n",
        "precisionList.append(precision_score(y_test, y_predict.round()))\n",
        "recallList.append(recall_score(y_test, y_predict.round()))\n",
        "F1List.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeJB4UVvcoaF",
        "outputId": "94231b65-27a3-4a6e-dcef-3eefe7ea63ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 58s 4ms/step - loss: 0.4539 - acc: 0.8059\n",
            "15000/15000 [==============================] - 38s 3ms/step\n",
            "0.8059125\n",
            "0.830582196406862\n",
            "0.7686\n",
            "0.7983899240407712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracyList.append(0.8059125)\n",
        "# precisionList.append(0.830582196406862)\n",
        "# recallList.append(0.7686)\n",
        "# F1List.append(0.7983899240407712)"
      ],
      "metadata": {
        "id": "us9BdKpmA9xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(accuracyList,open(\"/content/drive/MyDrive/acc_list.p\",\"wb\"))\n",
        "pickle.dump(precisionList,open(\"/content/drive/MyDrive/pre_list.p\",\"wb\"))\n",
        "pickle.dump(recallList,open(\"/content/drive/MyDrive/recall_list.p\",\"wb\"))\n",
        "pickle.dump(F1List,open(\"/content/drive/MyDrive/F1_list.p\",\"wb\"))\n"
      ],
      "metadata": {
        "id": "dGVeLup_Bbcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list = pickle.load(open(\"/content/drive/MyDrive/acc_list.p\",\"rb\"))\n",
        "pre_list = pickle.load(open(\"/content/drive/MyDrive/pre_list.p\",\"rb\"))\n",
        "recall_list = pickle.load(open(\"/content/drive/MyDrive/recall_list.p\",\"rb\"))\n",
        "F1_list = pickle.load(open(\"/content/drive/MyDrive/F1_list.p\",\"rb\"))"
      ],
      "metadata": {
        "id": "o65LVtg3DG1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(acc_list))\n",
        "print(len(pre_list))\n",
        "print(len(recall_list))\n",
        "print(len(F1_list))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-QPxdy7DrMU",
        "outputId": "6b8408eb-3f53-401a-e26b-c0d77c97a744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "12\n",
            "12\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Expriment 13 using simple RNN with 2 layers using pre compiled FastText word emmbadding **"
      ],
      "metadata": {
        "id": "2S5TK2R7Q9Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "path_to_glove_file = \"/content/drive/MyDrive/FastText(wiki-news-300d-1M).vec\"\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((10000, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i <10000:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 300,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO-4SkLlHO2_",
        "outputId": "32de3ee9-e96e-4660-dd80-2f5d4234fe4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 300)         3000000   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 32)                10656     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,014,881\n",
            "Trainable params: 14,881\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 48s 25ms/step - loss: 0.5215 - acc: 0.7434 - val_loss: 0.4976 - val_acc: 0.7583\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.4966 - acc: 0.7594 - val_loss: 0.4977 - val_acc: 0.7586\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 43s 24ms/step - loss: 0.4886 - acc: 0.7648 - val_loss: 0.4866 - val_acc: 0.7645\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 50s 29ms/step - loss: 0.4823 - acc: 0.7690 - val_loss: 0.4936 - val_acc: 0.7630\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 46s 26ms/step - loss: 0.4769 - acc: 0.7732 - val_loss: 0.4804 - val_acc: 0.7723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "acc_list.append(accuracy_score(y_test, y_predict.round()))\n",
        "pre_list.append(precision_score(y_test, y_predict.round()))\n",
        "recall_list.append(recall_score(y_test, y_predict.round()))\n",
        "F1_list.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhgdF0riOpqG",
        "outputId": "4b8a0db4-236b-41f0-9247-31694ed4b6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 100s 7ms/step - loss: 0.5366 - acc: 0.7586\n",
            "15000/15000 [==============================] - 134s 9ms/step\n",
            "0.758625\n",
            "0.8191719116376651\n",
            "0.663775\n",
            "0.7333314920178977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Expriment 14 using simple RNN with 3 layers using pre compiled FastText word emmbadding **"
      ],
      "metadata": {
        "id": "sZ8IxkL_RIxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 300,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7-OCMnOPetV",
        "outputId": "999b1f7b-44a8-493a-a9b8-d29d05c39762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 300)         3000000   \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 32)                10656     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,025,249\n",
            "Trainable params: 25,249\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 43s 24ms/step - loss: 0.5210 - acc: 0.7439 - val_loss: 0.5072 - val_acc: 0.7550\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 53s 30ms/step - loss: 0.4935 - acc: 0.7630 - val_loss: 0.4864 - val_acc: 0.7683\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 52s 30ms/step - loss: 0.4818 - acc: 0.7712 - val_loss: 0.4744 - val_acc: 0.7742\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 44s 25ms/step - loss: 0.4731 - acc: 0.7775 - val_loss: 0.4786 - val_acc: 0.7751\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 45s 25ms/step - loss: 0.4669 - acc: 0.7818 - val_loss: 0.4611 - val_acc: 0.7826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "acc_list.append(accuracy_score(y_test, y_predict.round()))\n",
        "pre_list.append(precision_score(y_test, y_predict.round()))\n",
        "recall_list.append(recall_score(y_test, y_predict.round()))\n",
        "F1_list.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb3Ew1AVQTWz",
        "outputId": "3f4f2b69-b331-4008-c7fe-55405b9e8d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 94s 6ms/step - loss: 0.4857 - acc: 0.7712\n",
            "15000/15000 [==============================] - 77s 5ms/step\n",
            "0.77120625\n",
            "0.7516829906773337\n",
            "0.8099916666666667\n",
            "0.7797487851396965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Expriment 15 using LSTM with 2 layers using pre compiled FastText word emmbadding **"
      ],
      "metadata": {
        "id": "g7szUaicRxcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "path_to_glove_file = \"/content/drive/MyDrive/FastText(wiki-news-300d-1M).vec\"\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((10000, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i <10000:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 300,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e10vOG2Rbtj",
        "outputId": "ddb0e3ee-f826-4e3a-c888-e19ebc1f8b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, None, 300)         3000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                42624     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,046,849\n",
            "Trainable params: 46,849\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 17s 7ms/step - loss: 0.4913 - acc: 0.7619 - val_loss: 0.4609 - val_acc: 0.7821\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 12s 7ms/step - loss: 0.4470 - acc: 0.7906 - val_loss: 0.4450 - val_acc: 0.7882\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 12s 7ms/step - loss: 0.4301 - acc: 0.8009 - val_loss: 0.4210 - val_acc: 0.8053\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 12s 7ms/step - loss: 0.4196 - acc: 0.8072 - val_loss: 0.4282 - val_acc: 0.8005\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 12s 7ms/step - loss: 0.4122 - acc: 0.8108 - val_loss: 0.4098 - val_acc: 0.8124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "acc_list.append(accuracy_score(y_test, y_predict.round()))\n",
        "pre_list.append(precision_score(y_test, y_predict.round()))\n",
        "recall_list.append(recall_score(y_test, y_predict.round()))\n",
        "F1_list.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-NFaOqTRpoL",
        "outputId": "1bf0fd9c-ebb7-44af-8794-5d09b668e5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 61s 4ms/step - loss: 0.4316 - acc: 0.8118\n",
            "15000/15000 [==============================] - 52s 3ms/step\n",
            "0.8118\n",
            "0.8251303441084463\n",
            "0.7913\n",
            "0.8078611536498213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Expriment 16 using LSTM with 2 layers using pre compiled FastText word emmbadding **"
      ],
      "metadata": {
        "id": "E5yzhESZxT1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 300,embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,))\n",
        "\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    epochs=5,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDrnHbr1TyM1",
        "outputId": "5273f479-65b4-490e-f087-7be0b713f293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, None, 300)         3000000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                42624     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,057,217\n",
            "Trainable params: 57,217\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1750/1750 [==============================] - 15s 8ms/step - loss: 0.4924 - acc: 0.7606 - val_loss: 0.4609 - val_acc: 0.7793\n",
            "Epoch 2/5\n",
            "1750/1750 [==============================] - 13s 7ms/step - loss: 0.4484 - acc: 0.7898 - val_loss: 0.4520 - val_acc: 0.7892\n",
            "Epoch 3/5\n",
            "1750/1750 [==============================] - 14s 8ms/step - loss: 0.4309 - acc: 0.8003 - val_loss: 0.4217 - val_acc: 0.8047\n",
            "Epoch 4/5\n",
            "1750/1750 [==============================] - 14s 8ms/step - loss: 0.4206 - acc: 0.8062 - val_loss: 0.4277 - val_acc: 0.8062\n",
            "Epoch 5/5\n",
            "1750/1750 [==============================] - 13s 7ms/step - loss: 0.4126 - acc: 0.8107 - val_loss: 0.4087 - val_acc: 0.8134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)\n",
        "y_predict = model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_predict.round()))\n",
        "print(precision_score(y_test, y_predict.round()))\n",
        "print(recall_score(y_test, y_predict.round()))\n",
        "print(f1_score(y_test, y_predict.round()))\n",
        "acc_list.append(accuracy_score(y_test, y_predict.round()))\n",
        "pre_list.append(precision_score(y_test, y_predict.round()))\n",
        "recall_list.append(recall_score(y_test, y_predict.round()))\n",
        "F1_list.append(f1_score(y_test, y_predict.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C1jN5afT4HM",
        "outputId": "10649dfd-04fa-4c44-f4cd-dc11d01608d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000/15000 [==============================] - 73s 5ms/step - loss: 0.4330 - acc: 0.8109\n",
            "15000/15000 [==============================] - 43s 3ms/step\n",
            "0.8109125\n",
            "0.7997469269703543\n",
            "0.8295375\n",
            "0.8143698613326789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "acc_list = pickle.load(open(\"/content/drive/MyDrive/acc_list.p\",\"rb\"))\n",
        "pre_list = pickle.load(open(\"/content/drive/MyDrive/pre_list.p\",\"rb\"))\n",
        "recall_list = pickle.load(open(\"/content/drive/MyDrive/recall_list.p\",\"rb\"))\n",
        "F1_list = pickle.load(open(\"/content/drive/MyDrive/F1_list.p\",\"rb\"))\n"
      ],
      "metadata": {
        "id": "RTjBn9DHlP10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(acc_list,open(\"/content/drive/MyDrive/acc_list.p\",\"wb\"))\n",
        "pickle.dump(pre_list,open(\"/content/drive/MyDrive/pre_list.p\",\"wb\"))\n",
        "pickle.dump(recall_list,open(\"/content/drive/MyDrive/recall_list.p\",\"wb\"))\n",
        "pickle.dump(F1_list,open(\"/content/drive/MyDrive/F1_list.p\",\"wb\"))\n"
      ],
      "metadata": {
        "id": "bwO2DYAQUeOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list1 = acc_list\n",
        "pre_list1 = pre_list\n",
        "recall_list1 = recall_list\n",
        "F1_list1 = F1_list\n",
        "for i in range(len(acc_list)):\n",
        "  acc_list1[i] = \"Expriment \"+str(i+1)+ \" \"+str(acc_list1[i])\n",
        "  pre_list1[i] = \"Expriment \"+str(i+1)+ \" \"+str(pre_list1[i])\n",
        "  recall_list1[i] = \"Expriment \"+str(i+1)+ \" \"+str(recall_list1[i])\n",
        "  F1_list1[i] = \"Expriment \"+str(i+1)+ \" \"+str(F1_list1[i])\n"
      ],
      "metadata": {
        "id": "9X1VLvADog_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list.sort()\n",
        "pre_list.sort()\n",
        "recall_list.sort()\n",
        "F1_list.sort()\n",
        "\n",
        "acc_list1.sort()\n",
        "pre_list1.sort()\n",
        "recall_list1.sort()\n",
        "F1_list1.sort()\n",
        "\n",
        "best_accurcy = ''\n",
        "best_precision = ''\n",
        "best_recall = ''\n",
        "best_F1_score = ''\n",
        "for i in range(len(acc_list)):\n",
        "  if str(acc_list[-1]) in str(acc_list1[i]):\n",
        "      best_accurcy = str(acc_list1[i])\n",
        "  if str(pre_list[-1]) in str(pre_list1[i]):\n",
        "      best_precision = str(pre_list1[i])\n",
        "  if str(recall_list[-1]) in str(recall_list1[i]):\n",
        "      best_recall = str(recall_list1[i])\n",
        "  if str(F1_list[-1]) in str(F1_list1[i]):\n",
        "      best_F1_score = str(F1_list1[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "HI4sx0qJtId7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_accurcy)\n",
        "print(best_precision)\n",
        "print(best_recall)\n",
        "print(best_F1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEUxX3o_uRzW",
        "outputId": "a0892d34-127a-419a-9510-7eae55f58e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expriment 8 0.8233625\n",
            "Expriment 1 0.8688641984829539\n",
            "Expriment 7 0.8681166666666666\n",
            "Expriment 7 0.8270912190929498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# According to above 16 expriments\n",
        "\n",
        "#Expriment 7 which simple LSTM with 2 layers is the best because it is giving the best out_put on both RECALL and F1-Score\n",
        "\n",
        "#thats why it is best among all others"
      ],
      "metadata": {
        "id": "gBVp6E9sxxer"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}